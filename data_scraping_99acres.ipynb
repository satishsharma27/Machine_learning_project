{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42a468c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data scraping from www.99acres.com\n",
    "# https://www.99acres.com/search/property/buy/chandigarh?city=73&preference=S&area_unit=1&res_com=R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d58855a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import3\n",
    "\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import os \n",
    "import time "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28b8aa38",
   "metadata": {},
   "source": [
    "Overview\n",
    "\n",
    "This code sets up the necessary tools and headers to scrape web data. It imports libraries for sending HTTP request,parsing\n",
    "HTML, and handling data. Additionally, it defines a user agent header to mimic a web browser, which can be useful to avoid \n",
    "getting blocked by some websites.\n",
    "\n",
    "-- import requests\n",
    "\n",
    "This line imports the requests module, which is a popular Python module used to send HTTP requests to websites.\n",
    "\n",
    "-- from bs4 import BeautifulSoup\n",
    "\n",
    "This line imports BeautifulSoup from bs4 module. Beautiful is library that is used for web scraping purpose to pull the data out of HTML and XML files. It creates a parse  tree that can be used to extract data in a hierarchical and more readable manner.\n",
    "\n",
    "-- import os\n",
    "\n",
    "This line imports the os module, which provides a way of interacting with the operating system. This could be used for task like creating directories, reading environment variables, etc.\n",
    "\n",
    "-- headers= {...}\n",
    "\n",
    "This line defines a dictionary called headers with a 'User-Agent' key. The values of this key is a string that represents a user agent string. \n",
    "\n",
    "The user agent string is used to tell the server about the browser and operating system of the user. Some websites server different content based on the user agent or even block certain user agents(often to prevent scarping). By defining a common browser's user agent string, this code is trying to mimic  a real browser request to potentially avoid  blocks  or get the same content  a real user would see.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61189395",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bb4376f6",
   "metadata": {},
   "source": [
    "Extracting Flats/Apartments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95dca329",
   "metadata": {},
   "source": [
    "- Yours_project_Directory\n",
    "  - DATA\n",
    "    -City\n",
    "     -Flats\n",
    "      -Societies\n",
    "       -Residential\n",
    "        -Independent House\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4cee7124",
   "metadata": {},
   "outputs": [],
   "source": [
    "City = 'chandigarh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30239c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User Agent\n",
    "# Headers set like below:\n",
    "# User Agent\n",
    "headers = {\n",
    "    'authority': 'www.99acres.com',\n",
    "    'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',\n",
    "    'accept-language': 'en-US,en;q=0.9',\n",
    "    'cache-control': 'no-cache',\n",
    "    'dnt': '1',\n",
    "    'pragma': 'no-cache',\n",
    "    'referer': f'https://www.99acres.com/flats-in-{City}-ffid-page',\n",
    "    'sec-ch-ua': '\"Chromium\";v=\"107\", \"Not;A=Brand\";v=\"8\"',\n",
    "    'sec-ch-ua-mobile': '?0',\n",
    "    'sec-ch-ua-platform': '\"macOS\"',\n",
    "    'sec-fetch-dest': 'document',\n",
    "    'sec-fetch-mode': 'navigate',\n",
    "    'sec-fetch-site': 'same-origin',\n",
    "    'sec-fetch-user': '?1',\n",
    "    'upgrade-insecure-requests': '1',\n",
    "    'user-agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/527.36 (KHTML, like Gecko) Chrome/107.0.0.0 Safari/537.36',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1085ea85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# folder structure\n",
    "\n",
    "import os\n",
    "\n",
    "# define the path to your project directory\n",
    "\n",
    "project_dir = \"D:\\data scraping data\"\n",
    "\n",
    "# define the subdirectory structure\n",
    "\n",
    "subdirectory = [\"Data\", f'Data/{City}',f\"Data/{City}/Flats\",f'Data/{City}/Societies',f'Data/{City}/Residential',f'Data/{City}/Independent House']\n",
    "\n",
    "\n",
    "# Create the directory structure\n",
    "\n",
    "for subdir in subdirectory:\n",
    "    dir_path = os.path.join(project_dir,subdir)\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "    else:\n",
    "        print(f\"Directory already exists:{dir_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e903ed42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter page number where you got error in last run.\n",
      "Enter page number to start from10\n"
     ]
    }
   ],
   "source": [
    "# put your start page number and end page number\n",
    "\n",
    "# page number  to start extraction data\n",
    "\n",
    "start = int(input(\"Enter page number where you got error in last run.\\nEnter page number to start from\"))\n",
    "\n",
    "end = start+10\n",
    "\n",
    "pagenumber = start\n",
    "\n",
    "req = 0\n",
    "\n",
    "flats = pd.DataFrame()\n",
    "\n",
    "try:\n",
    "    \n",
    "    while pagenumber<end:\n",
    "        i= 1\n",
    "        url = f'https://www.99acres.com/flats-in-{City}-ffid-page-{pageNumber}'\n",
    "        page = requests.get(url,headers=headers)\n",
    "        pagesoup = BeautifulSoup(page.content,\"html.parser\")\n",
    "        req=req+1\n",
    "        for soup in pagesoup.select_one\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2756e082",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
